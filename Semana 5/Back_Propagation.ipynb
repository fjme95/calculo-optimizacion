{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back Propagation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7HHS7GZashO+BoM57CqiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjme95/calculo-optimizacion/blob/main/Semana%205/Back_Propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6yzhrTMz1-B"
      },
      "source": [
        "https://github.com/programmingLearner/my-Back-Propagation/blob/19094029f9af63d789b4ce74c9b5dcce9d6aa71b/mybp.py#L274"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lc6upyWK2fp"
      },
      "source": [
        "import numpy as np\n",
        "from queue import Queue"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqinA_whykPp"
      },
      "source": [
        "# error handling function\n",
        "def error(warning):\n",
        "    print(warning)\n",
        "    # exit()\n",
        "\n",
        "# progress reporting function, may be disabled after debugging\n",
        "def progress(report):\n",
        "    print(report)\n",
        "    return\n",
        "\n",
        "\n",
        "class node:\n",
        "    # constructor\n",
        "    def __init__(self, operator, left_child, right_child = None, is_output = False):\n",
        "        # declaration of variables of this class\n",
        "        self.forward = 0    # forward value\n",
        "        self.backward = 0   # output gradient w.r.t. this node\n",
        "        self.parents = []   # pointers to parents nodes\n",
        "        self.left_child = None  # pointers to left child nodes\n",
        "        self.right_child = None # pointers to right child nodes\n",
        "        self.operator = ''  # operator type, e.g., input, const, +, *, sin, ...\n",
        "                            # operator is either input, const, unary or binary\n",
        "        self.cnt_parents = 0    # how many parents it has\n",
        "        self.cnt_ref = 0    # reference count, how many gradients w.r.t. this\n",
        "                            # node is added to self.backward\n",
        "        self.init = False   # if the node is fed with a value\n",
        "        self.bp_ed = False  # if back-prop from this node to its children nodes\n",
        "                            # has completed\n",
        "        self.is_output = is_output  # if the node is the output node\n",
        "        self.visited = 0    # for use in clear function when traversing\n",
        "\n",
        "        # initiate\n",
        "        self.check_valid_op(operator)\n",
        "        self.operator = operator\n",
        "        self.left_child = left_child\n",
        "        self.right_child = right_child\n",
        "        if operator in {'input', 'const'}:\n",
        "            return\n",
        "        if self.left_child == None:\n",
        "            error('Error: invalid operator without child!')\n",
        "        self.left_child.parents.append(self)\n",
        "        self.left_child.cnt_parents += 1\n",
        "        if operator in {'+', '*'}:  # binary operator\n",
        "            if self.right_child == None:\n",
        "                error('Error: invalid binary operator without child!')\n",
        "            self.right_child.parents.append(self)\n",
        "            self.right_child.cnt_parents += 1\n",
        "\n",
        "    # set as output node\n",
        "    def set_as_output(self):\n",
        "        self.is_output = True\n",
        "\n",
        "    # clear flags previously in the nodes\n",
        "    def clear(self):\n",
        "        self.forward = 0\n",
        "        self.backward = 0\n",
        "        self.cnt_ref = 0\n",
        "        self.init = False\n",
        "        self.bp_ed = False\n",
        "\n",
        "    def check_valid_op(self, operator):\n",
        "        if operator not in {'input', 'const', '+', '*', 'sin', 'cos', 'tan',\n",
        "                            'exp', 'log', 'neg', 'inv', 'relu'}:\n",
        "            error('Error: invalid operator type: ' + operator + ' !')\n",
        "\n",
        "    def check_initiated(self):\n",
        "        if not self.init:\n",
        "            error('Error: attempting to run graph without initializing!')\n",
        "\n",
        "    # feed value, initiate\n",
        "    def feed(self, value):\n",
        "        if self.operator not in {'input', 'const'}:\n",
        "            error('Error: attempting to feed value to non-input-or-const node!')\n",
        "        self.forward = value\n",
        "\n",
        "    # compute forwardly: compute the value of this node forwarding\n",
        "    # this function will return the node's parents nodes who is ready to compute forwardly\n",
        "    def compute_forward(self):\n",
        "        # valid check\n",
        "        if self.operator not in {'input', 'const'}:\n",
        "            if self.init == True:\n",
        "                error('Error: attempting to recalculate forwardly.')\n",
        "        # compute\n",
        "        if self.operator in {'+', '*'}: # binary operator\n",
        "            self.left_child.check_initiated()\n",
        "            self.right_child.check_initiated()\n",
        "            if self.operator == '+':\n",
        "                self.forward = self.left_child.forward + self.right_child.forward\n",
        "            else:\n",
        "                self.forward = self.left_child.forward * self.right_child.forward\n",
        "        elif self.operator not in {'input', 'const'}:   # unary operator\n",
        "            self.left_child.check_initiated()\n",
        "            if self.operator == 'sin':\n",
        "                self.forward = np.sin(self.left_child.forward)\n",
        "            elif self.operator == 'cos':\n",
        "                self.forward = np.cos(self.left_child.forward)\n",
        "            elif self.operator == 'tan':\n",
        "                self.forward = np.tan(self.left_child.forward)\n",
        "            elif self.operator == 'exp':\n",
        "                self.forward = np.exp(self.left_child.forward)\n",
        "            elif self.operator == 'log':\n",
        "                if self.left_child.forward <= 0:\n",
        "                    error('Error: attempting to feed a non-positive number into log!')\n",
        "                self.forward = np.log(self.left_child.forward)\n",
        "            elif self.operator == 'neg':\n",
        "                self.forward = 0 - self.left_child.forward\n",
        "            elif self.operator == 'inv':\n",
        "                if self.left_child.forward == 0:\n",
        "                    error('Error: attempting to feed 0 into inverse!')\n",
        "                self.forward = 1.0 / self.left_child.forward\n",
        "            elif self.operator == 'relu':\n",
        "                if self.left_child.forward > 0:\n",
        "                    self.forward = self.left_child.forward\n",
        "                else:\n",
        "                    self.forward = 0\n",
        "            else:\n",
        "                error('Error: invalid operator type while forwarding!')\n",
        "        self.init = True    # this should be in advance of find parents,\n",
        "                            # in case, e.g. b = a + a\n",
        "        # find parents ready for forwarding\n",
        "        list = []\n",
        "        tmp = None\n",
        "        for node in self.parents:\n",
        "            if tmp == node: # in case like b = a + a\n",
        "                continue\n",
        "            tmp = node\n",
        "            if node.operator in {'+', '*'}:\n",
        "                if node.left_child == self:\n",
        "                    if node.right_child.init == True:\n",
        "                        list.append(node)\n",
        "                else:\n",
        "                    if node.left_child.init == True:\n",
        "                        list.append(node)\n",
        "            else:\n",
        "                list.append(node)\n",
        "        return list\n",
        "\n",
        "    # computing gradient w.r.t the child of this node, adding it to that\n",
        "    # this function will return the node's children nodes who is ready to back-prop\n",
        "    def back_prop(self):\n",
        "        # special cases\n",
        "        if self.is_output == True:\n",
        "            if self.init == False:\n",
        "                error('Error: attempting to back-prop without forwarding in advance!')\n",
        "            self.backward = 1\n",
        "        if self.bp_ed == True:\n",
        "            error('Error: attempting to back-prop twice from the node!')\n",
        "        if self.cnt_parents != self.cnt_ref:\n",
        "            error('Error: attempting to back-prop in a wrong order!')\n",
        "        if self.operator in {'input', 'const'}:\n",
        "            self.bp_ed = True\n",
        "            return []\n",
        "        # compute\n",
        "        if self.operator in {'+', '*'}:\n",
        "            if self.operator == '+':\n",
        "                self.left_child.backward += self.backward\n",
        "                self.right_child.backward += self.backward\n",
        "            else:\n",
        "                self.left_child.backward += self.backward * self.right_child.forward\n",
        "                self.right_child.backward += self.backward * self.left_child.forward\n",
        "            self.left_child.cnt_ref += 1\n",
        "            self.right_child.cnt_ref += 1\n",
        "        else:\n",
        "            if self.operator == 'sin':\n",
        "                self.left_child.backward += self.backward * np.cos(self.left_child.forward)\n",
        "            elif self.operator == 'cos':\n",
        "                self.left_child.backward -= self.backward * np.sin(self.left_child.forward)\n",
        "            elif self.operator == 'tan':\n",
        "                self.left_child.backward += self.backward / ((np.cos(self.left_child.forward)) ** 2)\n",
        "            elif self.operator == 'exp':\n",
        "                self.left_child.backward += self.backward * np.exp(self.left_child.forward)\n",
        "            elif self.operator == 'log':\n",
        "                self.left_child.backward += self.backward / self.left_child.forward\n",
        "            elif self.operator == 'neg':\n",
        "                self.left_child.backward -= self.backward\n",
        "            elif self.operator == 'inv':\n",
        "                self.left_child.backward -= self.backward / (self.left_child.forward ** 2)\n",
        "            elif self.operator == 'relu':\n",
        "                if self.left_child.forward > 0:\n",
        "                    self.left_child.backward += self.backward\n",
        "            else:\n",
        "                error('Error: invalid operator type while back-prop!')\n",
        "            self.left_child.cnt_ref += 1\n",
        "        self.bp_ed = True\n",
        "        # find children who are ready to back-prop: (considering b = a + a)\n",
        "        list = []\n",
        "        if self.left_child.cnt_ref == self.left_child.cnt_parents:\n",
        "            list.append(self.left_child)\n",
        "        if self.operator in {'+', '*'}:\n",
        "            if self.right_child.cnt_ref == self.right_child.cnt_parents:\n",
        "                if self.right_child != self.left_child:\n",
        "                    list.append(self.right_child)\n",
        "        return list\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"forward: {self.forward}\\nbackward: {self.backward}\"\n",
        "\n",
        "# computational graph presented as DAG\n",
        "class graph:\n",
        "\n",
        "    # constructor\n",
        "    def __init__(self, input_nodes, const_nodes, output_nodes):\n",
        "        progress('Welcome to use zty automatic back-prop program, ' +\n",
        "              'make sure that you have indicated which unique node is the output.')\n",
        "        self.input_nodes = input_nodes\n",
        "        self.const_nodes = const_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "        self.visited_ind = 1    # the nodes in the graph is visited during a traversing\n",
        "                                # if its visited bit is the same as self.visited indicator\n",
        "        progress('Progress: computational graph imported.')\n",
        "\n",
        "    # feed value, initiate\n",
        "    def feed(self, input_value_list, const_value_list):\n",
        "        l = len(input_value_list)\n",
        "        if l != len(self.input_nodes):\n",
        "            error('Error: input value list does not match!')\n",
        "        for i in range(l):\n",
        "            self.input_nodes[i].feed(input_value_list[i])\n",
        "        l = len(const_value_list)\n",
        "        if l != len(self.const_nodes):\n",
        "            error('Error: const value list does not match!')\n",
        "        for i in range(l):\n",
        "            self.const_nodes[i].feed(const_value_list[i])\n",
        "        progress('Progress: computational graph fed.')\n",
        "\n",
        "    # clear flags previously in the DAG\n",
        "    def clear(self):\n",
        "        queue = Queue()\n",
        "        for elm in self.output_nodes:\n",
        "            queue.put(elm)\n",
        "            elm.visited = self.visited_ind\n",
        "        while not queue.empty():\n",
        "            # print(queue.queue)\n",
        "            node = queue.get()\n",
        "            node.clear()\n",
        "            if node.left_child is not None:\n",
        "                if node.left_child.visited != self.visited_ind:\n",
        "                    queue.put(node.left_child)\n",
        "                    node.left_child.visited = self.visited_ind\n",
        "            if node.right_child is not None:\n",
        "                if node.right_child.visited != self.visited_ind:\n",
        "                    queue.put(node.right_child)\n",
        "                    node.right_child.visited = self.visited_ind\n",
        "        self.visited_ind = 1 - self.visited_ind\n",
        "        progress('Progress: computational graph cleared.')\n",
        "\n",
        "    # compute forward\n",
        "    def compute_forward(self):\n",
        "        queue = Queue()\n",
        "        for elm in self.input_nodes:\n",
        "            queue.put(elm)\n",
        "        for elm in self.const_nodes:\n",
        "            queue.put(elm)\n",
        "        while not queue.empty():\n",
        "            node = queue.get()\n",
        "            preparing = node.compute_forward()\n",
        "            for elm in preparing:\n",
        "                queue.put(elm)\n",
        "        progress('Progress: computational graph forwarded.')\n",
        "\n",
        "    # back prop\n",
        "    def back_prop(self):\n",
        "        queue = Queue()\n",
        "        for elm in self.output_nodes:\n",
        "            queue.put(elm)\n",
        "        while not queue.empty():\n",
        "            # print(queue.queue)\n",
        "            node = queue.get()\n",
        "            preparing = node.back_prop()\n",
        "            for elm in preparing:\n",
        "                queue.put(elm)\n",
        "        progress('Progress: computational graph back-propagated.')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OMiAajiO54T",
        "outputId": "e80de639-7fd9-4886-bf37-7b5a62e459e1"
      },
      "source": [
        "x1 = node('input', None)\n",
        "x2 = node('input', None)\n",
        "\n",
        "c1 = node('const', None)\n",
        "\n",
        "A = node('+', x1, x2)\n",
        "B = node('*', A, c1, is_output=True)\n",
        "\n",
        "G = graph([x1,x2], [c1], [B])\n",
        "\n",
        "x_init = [1, 2]\n",
        "const_init = [4]\n",
        "\n",
        "G.feed(x_init, const_init)\n",
        "\n",
        "G.compute_forward()\n",
        "G.back_prop()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to use zty automatic back-prop program, make sure that you have indicated which unique node is the output.\n",
            "Progress: computational graph imported.\n",
            "Progress: computational graph fed.\n",
            "Progress: computational graph forwarded.\n",
            "Progress: computational graph back-propagated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRAsAl_cP78B",
        "outputId": "feebc0a3-8fbc-454c-dd07-39eb61d72196"
      },
      "source": [
        "x1.backward"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-7qnG4kUE3H",
        "outputId": "f7f63754-f8ee-4c82-e06d-214501a7a7aa"
      },
      "source": [
        "x1 = node('input', None)\n",
        "x2 = node('input', None)\n",
        "\n",
        "w0 = node('input', None)\n",
        "w1 = node('input', None)\n",
        "w2 = node('input', None)\n",
        "\n",
        "one = node('const', None)\n",
        "sigmoid = node('inv', node('+',\n",
        "    node(\n",
        "        'exp',\n",
        "         node(\n",
        "             'neg', \n",
        "               )\n",
        "              )\n",
        "         ), \n",
        "     one\n",
        "    ), is_output=True)\n",
        "G = graph([x1,x2], [w0, w1, w2, one], [sigmoid])\n",
        "x_init = [.5, .2]\n",
        "const_init = [1.0, 2.0, 3.0, 1]\n",
        "G.feed(x_init, const_init)\n",
        "G.compute_forward()\n",
        "G.back_prop()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to use zty automatic back-prop program, make sure that you have indicated which unique node is the output.\n",
            "Progress: computational graph imported.\n",
            "Progress: computational graph fed.\n",
            "Progress: computational graph forwarded.\n",
            "Progress: computational graph back-propagated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T340uhYaGbx",
        "outputId": "5cad0525-69c7-440e-cda9-db562d68d22e"
      },
      "source": [
        "sigmoid.forward"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9308615796566533"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_aCeACeaV0m",
        "outputId": "9fc6da1f-c2f0-40c5-aff8-21046e926547"
      },
      "source": [
        "real_sig = 1/(1+np.exp(-(1 + 2*.5 + 3*.2)))\n",
        "real_sig"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9308615796566533"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kaiq_KiCeLce",
        "outputId": "134edb42-c364-4a73-8e14-5a37e1395078"
      },
      "source": [
        "real_sig * (1-real_sig) * 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06435829917577342"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBCNzt72bRbu",
        "outputId": "76181c27-b29e-48d3-e23d-4bf951873ca8"
      },
      "source": [
        "w0.backward"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06435829917577351"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmjaaiKeld-v",
        "outputId": "27fc3b75-03a5-40a3-8811-c09526b949f3"
      },
      "source": [
        "G.clear()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: computational graph cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKDO-ajkgyUb"
      },
      "source": [
        "# for y = \\sum_i (x_i), return y\n",
        "def scalar_sum(x):\n",
        "    if type(x) is not list:\n",
        "        raise ValueError(f'x debe ser una lista, pero se recibió {type(x)}')\n",
        "    # TODO Revisar que todos sean nodos\n",
        "    n = len(x)\n",
        "    if n == 1:\n",
        "        return x[0]\n",
        "    sum = node('+', x[0], x[1])\n",
        "    for i in range(2, n):\n",
        "        sum = node('+', sum, x[i])\n",
        "    return sum\n",
        "\n",
        "def linear_combination(coef, x):\n",
        "    return scalar_sum([node('*', coef[i], x[i]) for i in range(len(coef))])\n",
        "\n",
        "def sigmoid(coef, x):\n",
        "    one = node('const', None)\n",
        "    return one, node('inv', node('+',node('exp',node('neg', linear_combination(coef, x))), one))\n",
        "\n",
        "def sigmod_scalar(coef, x):\n",
        "    return 1/(1+np.exp(-np.sum(coef*x)))"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8jl2s1Slh77",
        "outputId": "629f2e44-eec3-41ce-d764-7b3929584a74"
      },
      "source": [
        "x1 = node('input', None)\n",
        "x2 = node('input', None)\n",
        "\n",
        "w1 = node('input', None)\n",
        "w2 = node('input', None)\n",
        "\n",
        "one, aver = sigmoid([w1, w2], [x1, x2])\n",
        "aver.set_as_output()\n",
        "\n",
        "G = graph([x1, x2], [w1, w2, one], [aver])\n",
        "x_init = [.2, .7]\n",
        "const_init = [1.6, 2.0, 1]\n",
        "G.feed(x_init, const_init)\n",
        "G.compute_forward()\n",
        "G.back_prop()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to use zty automatic back-prop program, make sure that you have indicated which unique node is the output.\n",
            "Progress: computational graph imported.\n",
            "Progress: computational graph fed.\n",
            "Progress: computational graph forwarded.\n",
            "Progress: computational graph back-propagated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MQg3uo5rb8U",
        "outputId": "739ee259-217f-4f8d-99e2-a3fcbf93f129"
      },
      "source": [
        "aver.forward"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8481288363433407"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a55OAl0tqJSh",
        "outputId": "2b4e20e5-b1cb-4e40-bf48-b5af7739e764"
      },
      "source": [
        "sigmod_scalar(np.array(x_init), np.array(const_init[:2]))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8481288363433407"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxNlNKAHRsvQ"
      },
      "source": [
        "# Ejercicios\n",
        "\n",
        "- Agregar tanh a las posibles operaciones de los nodos\n",
        "- Codificar una regresión logística con los nodos"
      ]
    }
  ]
}